\documentclass[final]{beamer} % beamer 3.10: do NOT use option hyperref={pdfpagelabels=false}!

%\documentclass[final,hyperref={pdfpagelabels=false}]{beamer} % beamer 3.07: get rid of beamer warnings

\mode<presentation>{\usetheme{dsmanchester}}

% Portrait, A0 poster. Set scale as desired, but 1.o3 gives easily readable text when printed.
\usepackage[orientation=portrait, size=a0, scale=1.3]{beamerposter}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{adjustbox}
% Set height of page for use in arranging text boxes, after accounting for
% heading, footer etc. This is a bit of a hack, ideally latex should figure
% this out for itself!

\makeatletter
\newcommand{\ccell}[3][]{%
  \kern-\fboxsep
  \if\relax\detokenize{#1}\relax
    \expandafter\@firstoftwo
  \else
    \expandafter\@secondoftwo
  \fi
  {\colorbox{#2}}%
  {\colorbox[#1]{#2}}%
  {#3}\kern-\fboxsep
}
\makeatother
\definecolor{orange}{RGB}{224,115,104}
%% \AtBeginDocument{\setlength{\cmidrulekern}{0.3em}}


\newcommand{\rpm}{\raisebox{.2ex}{$\scriptstyle\rpm$}}

\newlength{\columnheight}
\setlength{\columnheight}{1025mm}
\setlength{\tabcolsep}{12pt}

                  
% Define the header information
\title{Unsupervised Task Discovery for \\ Multi-Task Acoustic Modeling}
\author{\large{\textit{Josh Meyer}}}
\institute{\texttt{joshua.richard.meyer@gmail.com  |  @\_josh\_meyer\_  |  jrmeyer.github.io}}


% Put any other packages or custom macros in here:



% Now start the actual poster
\begin{document}

% Header is automatically generated from the command defined in the theme
% file, the information above and the logos in the logo folder.


% Start of the body:
\begin{frame}
  \begin{columns}
    %% Leftmost column:
    \begin{column}{0.3\textwidth}
      % For some reason we need parbox to get it to arrange the boxes
      % with evenly spaced gaps
      \parbox[t][\columnheight]{.9\textwidth}{

        \vspace{1cm}
        
        \begin{block}{Abstract}
          \begin{itshape}   % italic abstract
            \begin{itemize}
            \item Multi-Task Learning works (good for low-resource languages)
            \item However, tasks are hard to make
            \item Better to discover tasks automatically
            \item Experiment with k-means on MFCCs
            \item Data == 1.5 hours of Kyrgyz audio-book
            \item Initial Results Promising
            \end{itemize}
          \end{itshape}
        \end{block}

        \vfill
        
        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \includegraphics[width=\linewidth]{figs/heigold-2013-dnn-c.png}
          \caption{Multi-Task Learning Architecture \\(Heigold et al. 2013)}
          \label{fig:mtl-dnn}
          \endminipage\hfill
        \end{figure}
        
        \vfill
        
        \begin{block}{\boxnumber Background}
          \begin{itemize}
          \item Multi-Task Learning in Acoustic Modeling
            \begin{itemize}
            \item Multilingual
              \begin{itemize}
              \item new language == new task
                \item e.g. English vs. Kyrgyz
              \end{itemize}
            \item Monolingual
              \begin{itemize}
              \item new linguistic encoding == new task
              \item e.g. vowels vs. consonants; monophones vs. triphones
              \end{itemize}
            \end{itemize}     
          \end{itemize}
        \end{block}

        \vfill

        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \centering
          \includegraphics[width=\linewidth]{figs/tree-net.png}
          \caption{Label Correspondance of Decision Tree / DNN \\ \hspace{5cm} (HTK Book \& Heigold et al. 2013)}
          \label{fig:mtl-dnn}
          \endminipage\hfill
        \end{figure}

        \vfill

        
        \begin{block}{\boxnumber GMM-HMM Alignment}
          \begin{itemize}
            \item All done in Kaldi
          \item Feature Extraction
            \begin{itemize}
            \item 13 PLP features, 25ms Hamming windows, 10ms shift, 16 frame left-context \& 12 frame right-context, CMVN
            \end{itemize}
          \item GMM Alignment
            \begin{itemize}
            \item Monophones: 1,000 Gaussians, 25 iterations EM // Triphones: 2,000 leaves \& 5,000 Gaussians, 25 iterations EM
            \end{itemize}
          \end{itemize}
        \end{block}
  
        \vfill


                \begin{block}{\boxnumber Clustering}            
          \begin{itemize}
          \item k-means Clustering
            \begin{itemize}
            \item A set number of clusters is discovered via TensorFlow's standard k-means clustering.
            \end{itemize}
          \end{itemize}
        \end{block}

                
      } % end of parbox
    \end{column}

    %% Next column:
    %% ============================================================
    \begin{column}{0.3\textwidth}

      \parbox[t][\columnheight]{.9\textwidth}{
        
        \vspace{.4cm}

                
                \begin{block}{\boxnumber Mapping Triphone States $\rightarrow$ Clusters}          
          \begin{itemize}
            \item All training examples aligned to triphone state are mapped to most common k-means cluster.
          \end{itemize}
                \end{block}

                
        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \includegraphics[width=\linewidth]{figs/aligned.png}
          \caption{GMM-HMM aligned Triphone States}
          \endminipage\hfill
        \end{figure}

        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \includegraphics[width=\linewidth]{figs/clustered.png}
          \caption{K-Means Discovered Clusters}
          \endminipage\hfill
        \end{figure}
        
        
        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \includegraphics[width=\linewidth]{figs/mapped.png}
          \caption{Voting \& Mapping of Triphone-States $\rightarrow$ Clusters}
          \endminipage\hfill
        \end{figure}

        \vfill


                
        \begin{block}{\boxnumber Cluster Contents}
          
          \begin{itemize}
          \item Started with 672 triphone states in Kaldi \& 1024 clusters in TensorFlow
          \item 185 new labels after mapping
            \begin{itemize}
            \item 75 w/ only one triphone state
              \begin{itemize}
              \item e.g. \{ \texttt{t+a-f} \}
              \end{itemize}
            \item 9 w/ $>1$ triphone of given phoneme
              \begin{itemize}
              \item e.g. \{ \texttt{t+a-f}, \texttt{g+a-p} \}
              \end{itemize}
            \item 39 w/ only vowels or only consonants
              \begin{itemize}
              \item e.g. \{ \texttt{t+a-f}, \texttt{p+o-k} \}
              \end{itemize}
            \end{itemize}
          \end{itemize}
        \end{block}

        \vfill
        
          \begin{table}[!htbp]
            \centering
            \label{tab:results}
            \begin{adjustbox}{width=\textwidth}
              \begin{tabular}{lllccrrr}
                \cmidrule[2pt]{2-7}
                &\multicolumn{2}{c}{Vowels} &&& \multicolumn{2}{c}{ Consonants}& \\
                \cmidrule[1pt]{2-7}
                &a  j & a  u           &&& k  r &     g n m&\\
                \textsc{Back Vowels} $\rightarrow$&\ccell{orange}{a  o} & a  ih          &&&  k p  &    s sh ch&\\
                &e  j & e  ih          &&& r ng & t k s p &\\
                &e  y &o  u            &&& d ch & \ccell{orange}{m ng}& $\leftarrow$ \textsc{Nasals}\\
                &u  ih  y & u  ih      &&& t k & t k h&\\
                &i  e  y &o  ih        &&& d z&t k s &\\
                &a  e  oe  j ih & j ih &&& l z  & t ch d&\\
                &a  ih  o  u  y        &&&& n p & t k zh b & \\
                &&&&&& t g b s sh z zh& \\
                \cmidrule[2pt]{2-7}
              \end{tabular}
            \end{adjustbox}
            \vspace{.5cm}
            \caption{Discovered Clusters of Triphone-States}
          \end{table}


                  \vfill
        
        \begin{block}{\boxnumber Multi-Task DNN Training Set-up}          
          \begin{itemize}    
          \item DNN Acoustic model training
            \begin{itemize}
            \item Multi-Task Time-Delay Neural Network
            \item 5-epochs, 11 $ReLU$ layers, 
            \item $\alpha_{initial}=0.0015$ $\rightarrow$ $\alpha_{final}=0.00015$
            \item Each task has penultimate + ultimate output layer
            \end{itemize}
          \end{itemize}
        \end{block}

        \vfill

        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \centering
          \includegraphics[width=.8\linewidth]{figs/1_point_2_1024.eps}
          \caption{Model Accuracy During Training (Simple Loss)}
          \endminipage\hfill
        \end{figure}

        

        
      } % end of parbox
    \end{column}

    
    %% Next column:
    %% ============================================================
    \begin{column}{0.3\textwidth}
      \parbox[t][\columnheight]{.9\textwidth}{
        \vspace{1cm}               % automatically nicely spaced out.

        
        \begin{block}{\boxnumber Testing Setup}
          \begin{itemize}
          \item k-folds cross-validation ($k==5$)
            \begin{itemize}
            \item 511 utterances for train
            \item 100 utterances for test
            \end{itemize}
          \item Decoded with 1-gram LM
            \begin{itemize}
            \item \textit{Acoustic model more import}
            \end{itemize}
          \end{itemize}
        \end{block}

        \vfill
        
        \begin{block}{\boxnumber Results: Traditional Weighting Scheme}
          \begin{itemize}
          \item Loss = $((1-\alpha)*MAIN + \alpha*AUX)$
          \item WER better than Baseline in 4/9 experiments
          \end{itemize}
        \end{block}

        
        \vfill
        

                  
          \begin{table}[!htbp]
            \centering
            \caption{WER\% for Traditional Weighting Scheme}
            \begin{adjustbox}{width=\textwidth}
              \begin{tabular}{lccc}
                \toprule
                & $\alpha = 0.1 $ & $\alpha = 0.2 $ & $\alpha = 0.3 $\\
                \midrule
                Single Task Baseline  &  \multicolumn{3}{c}{$57.55$ \raisebox{.33\height}{\footnotesize{$\pm 1.82$}}}     \\
                
                \textbf{+ 256 clusters}  &  $57.93$ \raisebox{.33\height}{\footnotesize{$\pm 1.63$}}   &  $57.04$ \raisebox{.33\height}{\footnotesize{$\pm 1.58$}}     & 57.66 \raisebox{.33\height}{\footnotesize{$\pm 1.24$}} \\
                
                \textbf{+ 1024 clusters}   & $57.69$ \raisebox{.33\height}{\footnotesize{$\pm 3.78$}}    & \textbf{56.99} \raisebox{.33\height}{\footnotesize{$\pm 3.08$}}    & $57.60$ \raisebox{.33\height}{\footnotesize{$\pm 0.79$}}  \\
                
                \textbf{+ 4096 clusters}   &  $57.25$ \raisebox{.33\height}{\footnotesize{$\pm 2.87$}}  & $58.07$ \raisebox{.33\height}{\footnotesize{$\pm 1.35$}}   &   $57.45$ \raisebox{.33\height}{\footnotesize{$\pm 0.32$}}  \\
                \bottomrule
              \end{tabular}
            \end{adjustbox}
          \end{table}


          \vfill
          
        
        \begin{block}{\boxnumber Results: Simple Weighting Scheme}
          \begin{itemize}
          \item Loss = $(MAIN + \alpha*AUX$)
          \item WER better than Traditional Loss
          \item WER better than Baseline in 6/9 experiments
          \end{itemize}
        \end{block}        

        \vfill
        
        
        \begin{table}[!htbp]
          \centering
          \caption{WER\% for Simple Weighting Scheme}
          \begin{adjustbox}{width=\textwidth}
            \begin{tabular}{lccc}
              \toprule
              & $\alpha = 0.1 $ & $\alpha = 0.2 $ & $\alpha = 0.3 $\\
              \midrule
              Single Task Baseline  &  \multicolumn{3}{c}{$57.55$ \raisebox{.33\height}{\footnotesize{$\pm 1.82$}}}     \\
              
              \textbf{+ 256 clusters}  &  $57.33$ \raisebox{.33\height}{\footnotesize{$\pm 2.49$}}   &  $58.02$ \raisebox{.33\height}{\footnotesize{$\pm 2.09$}}     & $57.18$ \raisebox{.33\height}{\footnotesize{$\pm 0.56$}} \\
              
              \textbf{+ 1024 clusters}   & $ 57.74$ \raisebox{.33\height}{\footnotesize{$\pm 3.06$}}    & \textbf{56.88}  \raisebox{.33\height}{\footnotesize{$\pm 1.33$}}    & $57.13  $ \raisebox{.33\height}{\footnotesize{$\pm 1.55$}}  \\
              
              \textbf{+ 4096 clusters}   &  $57.56$ \raisebox{.33\height}{\footnotesize{$\pm 2.53$}}  & $57.49$ \raisebox{.33\height}{\footnotesize{$\pm  3.17$}}   &  $57.31$ \raisebox{.33\height}{\footnotesize{$\pm 1.31$}}  \\
              \bottomrule
            \end{tabular}
          \end{adjustbox}
        \end{table}
        
        \vfill

        \begin{figure}[!htbp]
          \centering
          \minipage{\textwidth}
          \centering
          \includegraphics[width=.8\linewidth]{figs/dev_during_training.eps}
          \caption{Model Accuracy on Dev. Data During Training}
          \endminipage\hfill
        \end{figure}

        \vfill
        
                \begin{block}{\boxnumber Discussion}
          \begin{itemize}
          \item Good auxiliary tasks exist (we just need to find them)
          \item Initial results show small improvements, given good hyper-parameters
          \item Clustering in high-dimensional feature space isn't great
                  \begin{itemize}
                  \item Find better projections: LDA, source DNN activations (from well-resourced lang.)
                  \end{itemize}
                \item Big net overfits to both tasks
                            \begin{itemize}
                            \item add more tasks
                            \item use smaller net
                            \end{itemize}
          \end{itemize}
        \end{block}        

        \vfill
        


        
        
        \begin{block}{\boxnumber Acknowledgements}
          \footnotesize{This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. (DGE-1746060). Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation.}
        \end{block}

        
        }%parbox
    \end{column}
    
  \end{columns}
\end{frame}

\end{document}
